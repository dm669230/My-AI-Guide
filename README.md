# ğŸ§  Personal Document Q&A Assistant (LangChain + RAG + Vector DB)

A beginner-friendly project that turns your personal documents (PDFs, DOCX, TXT) into a smart assistant using **LangChain**, **OpenAI**, and **Chroma VectorDB**. Just upload files and start asking questions â€” it will find the right answers from your documents using **Retrieval-Augmented Generation (RAG)**.

---

## ğŸš€ Features

- ğŸ“„ Upload and read documents (PDF, DOCX, TXT)
- ğŸ” Ask questions about your uploaded files
- ğŸ§  Retrieval-Augmented Generation (RAG) using LangChain
- ğŸ”§ Optional tools like Calculator and Web Search
- ğŸ’¬ Clean Streamlit-based web interface
- âš¡ Powered by OpenAI LLMs + VectorDB (Chroma)

---

## ğŸ§° Tech Stack

| Component     | Technology Used                    |
|---------------|-------------------------------------|
| LLM           | OpenAI GPT-3.5 / GPT-4             |
| Framework     | LangChain                          |
| Embeddings    | OpenAI Embeddings                  |
| Vector DB     | ChromaDB                           |
| File Parsing  | pdfminer, python-docx, unstructured|
| Frontend      | Streamlit                          |
| Environment   | Python 3.8+                        |

---

## ğŸ“‚ Project Structure


personal-assistant/
â”‚
â”œâ”€â”€ app.py # Main Streamlit interface
â”œâ”€â”€ loader.py # File loader for PDFs, DOCX, TXT
â”œâ”€â”€ chunker.py # Text chunking logic
â”œâ”€â”€ embedder.py # Embedding & storing in ChromaDB
â”œâ”€â”€ rag_chain.py # RAG logic: retrieval + LLM response
â”œâ”€â”€ tools.py # Custom tools (calculator, etc.)
â”œâ”€â”€ config.py # Global constants and config settings
â”œâ”€â”€ .env # API keys and other environment vars
â”œâ”€â”€ requirements.txt # Required Python packages
â””â”€â”€ data/
â””â”€â”€ my_docs/ # Folder containing your uploaded files


## ğŸ§‘â€ğŸ’» Getting Started

### ğŸ”¹ 1. Clone the Repository

```bash
git clone https://github.com/your-username/personal-assistant.git
cd personal-assistant

ğŸ”¹ 2. Set Up Virtual Environment
# Create virtual environment
python -m venv venv

# Activate:
# On Windows
venv\Scripts\activate

# On Linux/macOS
source venv/bin/activate

ğŸ”¹ 3. Install Requirements
pip install -r requirements.txt

ğŸ”¹ 4. Set Up Environment Variables

Create a .env file in the root of the project with one of the following structures:

ğŸ§  For DeepSeek API
DEEPSEEK_API_KEY=your-deepseek-api-key
DEEPSEEK_API_BASE=https://api.deepseek.com/v1
DOCS_DIRECTORY=data/my_docs

ğŸ¤– For OpenAI API
OPENAI_API_KEY=your-openai-api-key
DOCS_DIRECTORY=data/my_docs

ğŸ”¹ 5. Run the Streamlit App
streamlit run app.py


Then open the browser link (usually http://localhost:8501)

âš™ï¸ How It Works

Upload documents â†’ PDF, DOCX, TXT

Extract and chunk text â†’ Break into manageable parts

Generate embeddings â†’ Using DeepSeek/OpenAI

Store in Chroma vector DB â†’ For similarity-based search

Ask questions â†’ Query is matched with relevant content

LLM responds â†’ Answer generated with document context

ğŸ›  Tools Integration (Optional)

Inside tools.py, you can add utility tools that the assistant can call when needed:

Tool	Purpose
Calculator	Solve math queries
Summarizer	Summarize large text content
SearchTool	Pull info from the web (optional)

Tools can be registered with LangChainâ€™s Tool API.

ğŸ“¦ requirements.txt
langchain
openai
chromadb
streamlit
tiktoken
unstructured
pdfminer.six
python-docx
python-dotenv

âœ… To-Do (Optional Improvements)

 Add chat history and memory support

 Dockerize the entire application

 Support multiple users with sessions

 Improve UI styling with Streamlit themes

 Add option to switch between LLM providers (DeepSeek/OpenAI/Ollama)

ğŸ§‘ Author

Vaibhav Srivastava
Python Developer | FastAPI | LLMs | Backend
ğŸ“§ vaibhav.srivastava405@gmail.com

ğŸ“ Mumbai, India
